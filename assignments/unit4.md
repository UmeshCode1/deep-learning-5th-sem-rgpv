# Unit 4 Assignment â€” RNNs, LSTM, Attention

Total Marks: 50 | Due: Two weeks from assignment date

A. Short Answers (10 marks)
1. Derive LSTM cell equations and explain each gate.
2. Define teacher forcing and exposure bias.

B. Problems (20 marks)
1. Character-level LSTM to generate text from a small corpus (e.g., Shakespeare tiny). Report training loss curve and 3 sample generations.
2. Sequence classification with bidirectional LSTM on IMDB-sentiment (or a tiny text dataset). Report accuracy and a confusion matrix.

C. Application/Analysis (15 marks)
1. Implement attention on top of the LSTM decoder (Bahdanau/Luong). Show attention heatmaps for 3 sequences.

D. Viva (5 marks)
- Prepare to discuss gradient clipping and why it helps RNN training.

Deliverables
- Notebook + report with plots and generated samples
